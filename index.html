<!DOCTYPE html>
<html><head><script async="" src="https://www.google-analytics.com/analytics.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-3974203-1', 'auto'); ga('send', 'pageview');</script>
<title>soumyadeepb08.github.io</title>

<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {
  background: white;
}

.content {
  max-width: 900px;
  margin: auto;
  background: white;
  padding: 10px;
}

.tab {
  overflow: hidden;
  border: 1px solid #ccc;
  background-color: #f1f1f1;
}

/* Style the buttons inside the tab */
.tab button {
  background-color: inherit;
  float: left;
  border: none;
  outline: none;
  cursor: pointer;
  padding: 14px 16px;
  transition: 0.3s;
  font-size: 17px;
}

/* Change background color of buttons on hover */
.tab button:hover {
  background-color: #ddd;
}

/* Create an active/current tablink class */
.tab button.active {
  background-color: #ccc;
}

/* Style the tab content */
.tabcontent {
  display: none;
  padding: 6px 12px;
  border: 1px solid #ccc;
  border-top: none;
}

li{
    margin: 15px 0;
}
</style>
</head>
<body>

<div class="content">

  <div class="tab">
    <button class="tablinks active" onclick="openT(event, 'Home')" id="defaultOpen">Home</button>
    <button class="tablinks" onclick="openT(event, 'Me as a Learner')">Me as a Learner</button>
    <button class="tablinks" onclick="openT(event, 'Research Activities')">Research Activities</button>
    <button class="tablinks" onclick="openT(event, 'Awards')">Awards</button>
    <button class="tablinks" onclick="openT(event, 'Paintings')">Paintings</button>
    <button class="tablinks" onclick="openT(event, 'Community Outreach')">Community Outreach</button>
  </div>

<div id="Home" class="tabcontent" style="display: block;">



<img align="left" src="https://drive.google.com/uc?id=1rPZYv3Pn_nU7pJ7pVuHo9g2CSlRRVm2r" width="130" alt="sb">
<p align="left">
    <b> &ensp;  Soumyadeep Bhattacharjee </b><br>
        &ensp;  DoB: November, 2008 <br>
        &ensp;  Grade 9, High School Student <br>
        &ensp;  Williamsville East High School<br>
        &ensp;  8730 Transit Road, Williamsville, New York, 14051<br>
        &ensp;  Email: sbhattac@buffalo.edu<br>
        &ensp;  YouTube: <a href=https://www.youtube.com/channel/UC_2TwTHSgzL9kTKcPuecnUA> https://www.youtube.com/channel/UC_2TwTHSgzL9kTKcPuecnUA </a>
    </p>

<p><br>
 
Soumyadeep Bhattacharjee is a Middle School student, who dreams of building a humanoid robot that will be smart enough to learn any repititive tasks to support humans, while, the exclusive focus of the human race will be innovation and exploration within as well as beyond our universe. Soumyadeep is bestowed with an enormous passion about Mathematics and Computer Science. He has been homeschooled most of his elementary, middle school years and joined traditional schooling system only after shifting to New York in 2019, when he joined grade 7 at Transit Middle School. His present research intrests lie in building intelligent Internet-Of-Things (IOT) systems for various real world applications using innovative applications of Artificial Intelligence(AI), Machine Learning(ML), and Deep Learning(DL) Techniques. He is advised by Professor <a href="https://cse.buffalo.edu/~wenyaoxu/">Wenyao Xu<a> from the Computer Science &amp; Engineering Dept., University at Buffalo.<br>
<br>
</a></p><a>


<h2> Recent Updates : </h2>
<ul>
  <li> Research Paper "VoiceLens: A Multi-class Disease Classification Model through Daily-Life Speech Data", accepted into IEEE CHASE 2021 (<a href="https://conferences.computer.org/chase2021/">IEEE/ACM Conference on Connected Health Applications, Systems, and Engineering Technologies</a>)(<a href="https://conferences.computer.org/chase2021/students.html">Received NSF Travel Grant</a>).
  <li> Research Paper "Anomalous Pattern Recognition in Vital Health Signals via Multimodal Fusion", accepted into EAI BODYNETS 2021 (<a href="https://bodynets.eai-conferences.org/2021/?fbclid=IwAR2KmTUcrwKPF2rm32_Pn_FI40wrvEfRBq-SwydGX6ZpJCOzE8zy7y6P3VI">EAI International Conference on Body Area Networks: Smart IoT and big data for intelligent health management</a>) (<a href="https://youtu.be/swlJ30cag28">Video Presentation</a>)(Received Best Paper Award).
<li> <a href="https://www.onr.navy.mil/nsap/">2021 Navy and Marine Corps Office of Naval Research (ONR)</a> <i>Award for Scientific or Engineering Excellence</i></li>
<li>Advancement to the 2022 SENIOR <i>Research and Engineering Design Division</i></li>
<li><a href="https://ny-trfsef.zfairs.com/">2021 Terra Fairs</a> <i>Highest and Grand Award</i></li>, <a href= "https://studio.youtube.com/video/6h8jRF5_R3w/edit">Presentation</a>
<li>Invited to participate in the <a href="https://www.maa.org/math-competitions/american-invitational-mathematics-examination-aime">AIME 2021<a>(American Invitational Mathematics Examination)</li>
<li><i>Special Achievement Roll</i> in AMC 10 2021</li>
<li><a href="https://www.societyforscience.org/broadcom-masters/2020-top-300-masters/">2020 Top 300 Broadcom MASTERS</a>:</li>
<li>Individual rank 3rd, Countdown rank 1st, Team Rank 1st, Western New York Mathcount Chapter, Feb 2020.</li>
<li><i>International Junior Honor Society</i> Honorary Lifetime Member and <i>Young Acheivers Leadership Academy (YALA) Singapore</i> Honorary Leader 2020</li>
</ul>

</div>

<div id="Me as a Learner" class="tabcontent" style="display: none;">


<p>
</p><h2> Me as a Learner : </h2>
</p><h3> Courses Taken Outside of School Curriculum</h3>
<ul style="line-height: 0.5">
<li><b>University Computer Science 2</b> <i> E-IMACS,</i> A+,98%</li>
<li><b>CS50's Introduction to Artificial Intelligence with Python</b>, <i>HavardX Edx</i></li>
<li><b>CS50's Introduction to Game Development</b>, <i>HavardX Edx</i></li>
<li><b>Data Science Specialization</b>, <i>HavardX Edx</i></li>
<li><b>Object Oriented Programming in Java Specialization</b></li>
</ul>
</p><h3> Courses Taken Outside of School Curriculum during Elementary School Years [On or before 2019]</h3>
<ul style="line-height: 0.5">
<li><b>Honors Algebra 1</b> <i>Centre for Talented Youth (CTY), John Hopkins University, USA,</i> A+, 99%</li>
<li><b>Physical Science</b> <i>Centre for Talented Youth (CTY), John Hopkins University, USA,</i> A+, 99%</li>
<li><b>Introduction to Counting and Probability</b> <i> Art of Problem Solving (AOPS),</i> A</li>
<li><b>Introduction to Geometry</b> <i> Art of Problem Solving (AOPS),</i> A+</li>
<li><b>Introduction to Python</b> <i> Art of Problem Solving (AOPS),</i> A-</li>
<li><b>Introduction to Counting and Probability</b> <i> Art of Problem Solving (AOPS),</i> A</li>
<li><b>Precalculus</b> <i> Art of Problem Solving (AOPS),</i> A</li>
<li><b>Calculus 1</b> <i>MITX Edx</i>, A+</li>
<li><b>Introduction to Computer Science using Python</b> <i> Edx MITx,</i> A</li>
<li><b>Latin 1</b> <i>The Lukeion Project,</i> A</li>
<li><b>Latin 2</b><i>The Lukeion Project</i> A</li>
<li><b>University Computer Science 1</b> <i>E-IMACS</i> A+, 99%</li>
</ul>

</div>

<div id="Research Activities" class="tabcontent" style="display: block;">
<h2>Papers</h2>
<p>
<li>VoiceLens: A Multi-class Disease Classification Model through Daily-Life Speech Data; Soumyadeep B, Wenyao Xu; <i>IEEE/ACM Conference on Connected Health Applications, Systems, and Engineering Technologies (IEEE CHASE 2021)</i></li>
<li>Anomalous Pattern Recognition in Vital Health Signals via Multimodal Fusion; Soumyadeep B, Huining Li, Wenyao Xu; <i>EAI International Conference on Body Area Networks: Smart IoT and big data for intelligent health management (EAI BODYNETS 2021)</i> <a href="https://youtu.be/swlJ30cag28">Video Presentation</a>.</li>
</p>
<h2>Projects: </h2>
<hr>
<h3>VoiceLens: Disease Screening through Voices and Daily-Life Conversation</h3>
<p>
<img align="Centre" src="https://drive.google.com/uc?id=1YhzC_2ou39mItW9Rm8pUPOJBr4NMhOn-" width="850"  alt="healthchair">

</p>
<br>
In this project, we present a disease-specific classification of pathology signals based on voice samples. The proposed method enables a proactive, deep learning based sequential audio analysis and classification framework that combines the effectiveness of the powerful Mel-Frequency-Cepstral-Coefficients (MFCC) within a two-phase classification framework to build an accurate disease prediction. The first phase of pathology detection analysis captures the fine-grained details of these disorders and their sequential variation patterns within a stacked Long Short-Term Memory (LSTM) network to make the baseline binary detection (Healthy Vs. Pathology). In the second phase, the potential pathology samples are then investigated by a deep multi-layer learned descriptor to accurately identify the disease condition. The present research has evaluated the performance of the system using the large scale Saarbruecken Voice Database comprising of samples from 2000 individuals with 71 disease patterns including Laryngel Cancers, Dish-Syndrome and Parkinson's disease. Unlike most of the existing methods, which simplify the original multi-class voice pathology detection problem by formulating a binary classifier that considers all pathology classes as a single non-healthy category, the main advantage of the proposed model is that it is sufficiently generic, real time, and can effectively distinguish multiple pathology classes within an integrated multi-class framework. The experimental results show remarkable improvement in the system performance by reporting an accuracy up to 97.5% in binary classification experiment setting, where the model also obtains 98.00% and 97.13% for F1-Score and Recall. The proposed system reports around 15% (and 12%) average gain in the accuracy (and F1-score) in a multi-class scenario with as many as 7 categories across 6 different pathology classes.
</br>
<hr>
<p>
<h3>Social Engagement Interactive Prototype</h3>
<img align="Centre" src="https://drive.google.com/uc?id=14D2_CNSpXsmueciUndseOqoM8JU2szfH" width="850"  alt="alexaproject">
</p>
<br>
In this project, we develop an interactive prototype between users and Alexa chatbot that integrates mental health assessment and mindfulness intervention in a closed-loop fashion to reduce loneliness and depression and improve quality of life in community-dwelling older adults. Specifically, we employ Alexa to daily query some mental health related questions. The question poll consists of CAMS-R, PHQ-2, GAD-2, PSS-4, Sleep Disturbance short form, fatigue, UCLA Loneliness Scale-8, Sleep Hygiene Index, and negative mood survey. These questions are designed to identify mental health related high-risk symptoms, including fatigue, loneliness, sleep quality, mindfulness, depression, stress, and negative mood. Once the user launches a request for interaction, Alexa will randomly select the questionnaire set to ask the user corresponding questions. The definite answers are recorded via Alexa interface, and are stored in the local database. Based on the user provided answers, we will develop a personalized mindfulness activity recommendation algorithm to provide just-in-time mindfulness coaching service for users with mental health problems. After receiving the recommended list of mindfulness activities through Alexa, the user responds to execute daily mindfulness practice. The type, amount, and quality of daily completed mindfulness will affect the user’s behavior patterns and life habits. The changes of the user's behavior patterns and lifestyle will alter symptom assessment. Then, Alexa will update the recommendation list of mindfulness practices based on the user’s new symptoms and deliver it to the user. After that, the user will respond and continue another round of intervention. Therefore, such a closed-loop mindfulness intervention scheme can iteratively improve user’s high-risk symptoms and solve mental health problems. 
</br>
<b>Youtube Link:</b> <a href="https://youtu.be/yvTCaiA2Wto">https://youtu.be/yvTCaiA2Wto</a>
<hr>
<p>
<h3>Vital-Chair: Multimodal Non-Invasive Vital Signal Assessment in Daily Life</h3>
<img align="Centre" src="https://drive.google.com/uc?id=1UvdP6viKmC1k7fNotR-6dV_oKG4_Nj9x" width="850"  alt="alexaproject">
</p>
<br>

Increasingly, care-giving to senior citizens and patients requires monitoring of vital signs of  heartbeat, respiration and blood pressure for an extended period of time.In this paper, we propose an unobtrusive multimodal machine learning based synchronized biological signal monitoring process deployed into a chair setup that may execute a continual health observation task without interrupting the  seat occupant's daily activities. A cepstral based peak fusion technique is introduced to obtain a robust characterization of each biological signal that combines the list of dominant peaks in the input signal and its corresponding cepstrum. This works as an input to the following multimodal anomaly detection process that not only enables an accurate identification and localization of aberrant signal patterns, but also facilitates the proposed model to adopt an individual's unique health characteristics over time. In this work, we use ECG (Electrocardiogram), Femoral Pulse, PPG (Photoplethysmogram), and Body Temperature to monitor an individual's health condition. An extensive analysis that demonstrates performance both in the publicly available datasets as well as our real-life lab experimental settings with $10$ participants over a wide range of ages.
</br>
<hr>
</div>

<div id="Awards" class="tabcontent" style="display: none;">

<h2> Recent Awards / Recognitions : </h2>

<ul>
  <li> Received <a href="https://conferences.computer.org/chase2021/students.html">NSF Travel Grant</a> for Research Paper "VoiceLens: A Multi-class Disease Classification Model through Daily-Life Speech Data", accepted into IEEE CHASE 2021 (<a href="https://conferences.computer.org/chase2021/">IEEE/ACM Conference on Connected Health Applications, Systems, and Engineering Technologies</a>).
  <li> Received Best Paper Award for Research Paper "Anomalous Pattern Recognition in Vital Health Signals via Multimodal Fusion" at EAI BodyNets 2021 <a href = "https://bodynets.eai-conferences.org/2021/?fbclid=IwAR2KmTUcrwKPF2rm32_Pn_FI40wrvEfRBq-SwydGX6ZpJCOzE8zy7y6P3VI">(EAI International Conference on Body Area Networks: Smart IoT and big data for intelligent health management)</a></li>
<li> <a href="https://www.onr.navy.mil/nsap/">Navy and Marine Corps Office of Naval Research (ONR)</a> Award for Scientific or Engineering Excellence</li>
<li>Advancement to the 2022 SENIOR Research and Engineering Design Division</li>
<li><a href="https://ny-trfsef.zfairs.com/">Terra Fairs</a> Highest and Grand Award</li>
<li>Selected among the New York State Toppers in Mathcounts 2021</li>
<li>Invited to participate in the <a href="https://www.maa.org/math-competitions/american-invitational-mathematics-examination-aime">AIME 2021<a> (American Invitational Mathematics Examination)</li>
<li>Special Achievement Roll in AMC 10 2021</li>
<li><a href="https://www.societyforscience.org/broadcom-masters/2020-top-300-masters/">2020 Top 300 Broadcom MASTERS</a></li>
<li>Individual rank 3rd, Countdown rank 1st, Team Rank 1st, Western New York Mathcount Chapter, Feb 2020.</li>
<li>2nd rank, Honor Roll in Buffalo region in AMC8, 2019</li>
<li>5th rank in the <a href="https://sites.google.com/a/unca.edu/contest/wr3_19?authuser=0">Level-3 NC State Super Competition</a> Invitational Final round 2019, at UNC Asheville, May 2019</li>
<li>Selected for <a href="https://catalog.uncc.edu/preview_program.php?catoid=27&poid=7169">ESCROW program</a> in University of North Carolina at Charlotte to take college credit courses while enrolled in homeschool from Fall 2019.</li>
<li>1st rank in Level-3, <a href="https://cstem.uncc.edu/sites/cstem.uncc.edu/files/media/UNC%20Charlotte%20Super%20Competition%202019%20results.pdf">UNC Charlotte Super Competition</a> for NC High School Students, March 2019</li>
<li>Magna Cum Laude Award (3rd rank) in National Latin Exam (NLE), Latin1, held during Spring 2019</li>
</ul>

<h2>Earlier Awards / Recognitions during Elementary School Years : </h2>

<ul>
<li>Invited to become a member of the <b><i>Julian C. Stanley Study of Exceptional Talent (SET)</i></b> at Johns Hopkins University's Center for Talented Youth (CTY), August, 2018
</li>
<li><b><i>SAT</i></b> Spring 2018 (Math Score: 790 out of 800 & EBRW Score 560 out of 800)</li>
<li><b><i>PSAT 8/9</i></b> in Spring 2018 (Math Score: 720 out of 720 & EBRW Score 520 out of 720)</li>
<li>Member of the middle school team, which secured 1st place in <b><i>Mathematical Puzzle Program (MaPP)</i></b> at UNC Charlotte in April 2018.</li>
<li>Recognized as the Top Scorer 2018 in the <b><i>Duke University Talent Search Program (Duke-TIP)</i></b> for gifted kids</li>
<li><b><i>School and College Aptitude Test (SCAT)</i></b> score of 99 percentiles for Grade 4 in 2015 conducted by the John Hopkins University (JHU), USA, with Award of High Honor</li>
<li>Gold Medal (Rank 3rd) for Grade 3 in <b><i>Singapore Kangaroo Mathematics Contest (KMC)</i></b> 2016, Singapore.</li>
<li>Gold Medal (Singapore Rank 7th & Intl Rank 9th) for Grade 3, <b><i>Singapore and Asian School Mathematics Olympiad (SASMO)</i></b> 2016, Singapore</li>
<li>Gold Medal (Singapore Rank 5th, International Rank 7th) for Grade 3 in <b><i>Singapore International Math Olympiad Challenge (SIMOC)</i></b> 2016,Singapore.</li>
<li>Silver Medal and Star International Award for Grade 3 in Invitational round of <b><i>Asian International Mathematics Olympiad (AIMO)</i></b> 2015, where the Olympiad winners from respective countries join for the final round of contest.</li>
</ul>

</div>
<div id="Paintings" class="tabcontent" style="display: none;">
<ul>
<li><iframe src="https://drive.google.com/file/d/1qMGq8qV-axCn0Ef2GTHt6nwN2Kyaj6nF/preview" width="640" height="480" allow="autoplay"></iframe></li>
<li><iframe src="https://drive.google.com/file/d/1UAscDu9u-zZ_hWKXVdH7P-_3VnSyIQba/preview" width="640" height="480" allow="autoplay"></iframe></li>
<li><iframe src="https://drive.google.com/file/d/1GOQZJJXL-ZbUrcwTmYOwAjrgjJ5DG9nq/preview" width="640" height="480" allow="autoplay"></iframe></li>
<li><iframe src="https://drive.google.com/file/d/1uDql2xsok2_XY7E0LpTBEFyDquJLZl8a/preview" width="640" height="480" allow="autoplay"></iframe></li></ul>
</div>
<div id="Community Outreach" class="tabcontent" style="display: none;">
<li><b>STEM Ambassador</b> at University at Buffalo, Gifted Math Program</li>
<li>Teaching Assistant GMP3 ( Analytical Geonmetry, for grade 8/9 students) at University at Buffalo, Gifted Math Program</li>
<li>Summer Instructor for Computer Science at Community Academic Center, SUNY Buffalo State College </li>
<li>Scientific Experiment Demonstrator at Rochester Maker Faire</li>
<br>
<b>Photos</b>
<li><iframe src="https://drive.google.com/file/d/1O7sn_Gn6CP5bpVy1xVaiO2vfYP0UK6zp/preview" width="640" height="480" allow="autoplay"></iframe></li>
</div>

<script>
function openT(evt, Name) {
  var i, tabcontent, tablinks;
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }
  document.getElementById(Name).style.display = "block";
  evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



</body></html>
